
# Класифікація коментарів по типам токсичності 

## Огляд

Цей проект використовує машинне навчання для категоризації онлайн-коментарів на шість категорій: токсичні, особливо токсичні, непристойні, загрози, образи та ненависть до особистості.

## Структура Проекту

Репозиторій організований у кілька каталогів та файлів, кожен з яких виконує певну роль у процесі машинного навчання:

- **EDA/**: Jupyter ноутбуки (`graphics.ipynb` та `words.ipynb`) для дослідження даних (EDA) для розуміння наборів даних.
- **src/**: Вихідний код проекту.
  - **data/**: Файли даних та скрипти для їх обробки.
    - `test.csv`, `train.csv`: CSV файли для тренування та тестування моделей.
    - `key_words.json`: Ключові слова, що використовуються для фільтрації та категоризації коментарів, генеруються у файлі train.py.
    - `prepared_train.csv`, Оброблений файл train.csv, генерується також у train.py
    - `submission.csv`: Файл для подання з прогнозованими категоріями.
  - **models/**: Збережені ваги попередньо навчених моделей як `.joblib` файли для кожної категорії токсичності. А також збереженний TfidfVectorizer.
  - **train.py**: Оброблює тренувальні дані з train.csv та навчає моделі.   
  - **prediction.py**: Оброблює дані з test.csv та зберігає у файл submission.csv ймовірності кожної категорії токсичності.
  - **prepare_text.py**: Містить функції для обробки тексту та вхідного датасету.
  - **make_dictionary.py**: Містить функції для складання словаря, який необхідний для навчання.
  - **cut_non_toxic.py**: Видаляє з навчального датасету не потрібні для навчання рядки.
- **tests/**: Юніт-тести для забезпечення цілісності та правильності коду.
- **inference.py**: Заванатажує ваги моделей та робить передбачення для даного тексту. Детальніше про нього буде нижче.

## Початок роботи

### Передумови

- Python 3.x
- Менеджер пакетів pip

### використані бібліотеки

- pandas
- matplotlib
- joblib
- nltk
- scikit-learn

### Встановлення

1. Клонуйте репозиторій.
2. Налаштуйте віртуальне середовище:
   ```sh
   python -m venv venv
   ```
3. Активуйте віртуальне середовище:
   - У Windows:
     ```sh
     .\venv\Scripts\activate
     ```
   - На Unix або MacOS:
     ```sh
     source venv/bin/activate
     ```
4. Встановіть необхідні залежності:
   ```sh
   pip install -r requirements.txt
   ```

### Використання

1. Запустіть ноутбуки EDA, щоб візуалізувати та зрозуміти дані:
    ```sh
   jupyter notebook EDA/graphics.ipynb
    ```

2. Навчіть моделі за допомогою `src/train.py`.
3. Зробіть прогнози використовуючи навчені моделі за допомогою `src/prediction.py`.

## Тестування

Щоб запустити юніт-тести, використовуйте наступну команду:

```sh
pytest tests/
```

## Inference скрипт

Присутній скрипт який завантажить моделі та зробить передбачення для наданого тексту.
Для цього виконайте наступні команди:
   ```sh
   pip install nltk~=3.8.1 pandas~=2.1.3 joblib~=1.3.2 requests~=2.31.0 scikit-learn~=1.3.2
   ```
Завантажте файл `inference.py`. Та запустіть його з наступними параметрами:

| Flag | Long Form  | Description                     |
|------|------------|---------------------------------|
| -d   | --data     | Path to a CSV file to process   |
| -o   | --output   | Path to output of prediction    |

### Приклад
   ```sh
    python3 inference.py -d test.csv -o sub.csv
   ```

де `test.csv` це ваш файл з даними з наявними колонками `id` та `comment_text`, а `sub.csv` це файл в який ви хочете записати результат. 